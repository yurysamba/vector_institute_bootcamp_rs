{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h1>NARM Demo on YOOCHOOSE Dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Introduction to Method**\n",
    "- **Code**\n",
    "    - **Data**\n",
    "        - **Data Loading**\n",
    "        - **Data Preprocessing**\n",
    "        - **Data Loader**\n",
    "    - **Model**\n",
    "         - **Model Definition**\n",
    "         - **Metrics for Method**\n",
    "    - **Training, Validation and Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method covered in this demo is <a href=\"https://arxiv.org/pdf/1711.04725.pdf\" title=\"Neural Attenntive Session-based Recommendation\">**Neural Attenntive Session-based Recommendation**</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<style>\n",
    "img {\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://user-images.githubusercontent.com/34673511/188919387-1d514803-32fe-4b7a-907b-c3e41171776f.PNG\" alt=\"\" style=\"width:50%;>\n",
    "<figcaption align = \"center\"></figcaption>\n",
    "</figure>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In e-commerce scenarios where user profiles are invisible, session-based recommendations are proposed to generate recommendation results from short sessions. In previous works, only sequential behavior in the current session was considered, while the **user's main purpose** in the current session was neglected. The aim of this method is to propose a Neural Attentive Recommendation Machine (NARM) to solve this problem. To model the user's sequential behavior and capture the user's main purpose in the current session, **a hybrid encoder with an attention mechanism** is developed, which is later merged into a unified session representation. Using this unified session representation, the recommendation scores for each candidate item are computed. The NARM is trained by jointly learning item and session representations. NARM also performs significantly better on long sessions, which demonstrates its advantage of modeling the user's sequential behavior and main purpose simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<style>\n",
    "img {\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://user-images.githubusercontent.com/34673511/188919520-d7588b06-edd9-4ade-aa4d-9ba66aa78646.png\" alt=\"\" style=\"width:80%;>\n",
    "<figcaption align = \"center\"><b>Global recommenders model the user's whole sequential behavior to make recommendations, while local recommenders capture the user's primary motivation for making recommendations. Each recommender produces a recommendation score, which is displayed above the items. (b) shows the item in the red dashed box as being more relevant to the user's current intention. As the item's importance increases, the red line gets thicker.   </b></figcaption>\n",
    "</figure>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xMTtie7TQjR-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import pickle\n",
    "import operator\n",
    "import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "from os.path import join\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import Variable\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDHGBsYwDeA1",
    "outputId": "3b4eccc5-f34a-47d1-81fe-70d4b9a5b050"
   },
   "outputs": [],
   "source": [
    "path_to_data = \"/ssd003/projects/aieng/public/recsys_datasets/yoochoose/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous demo, we trained and evaluated this model using the **YOOCHOOSE dataset**. This dataset was released as part of the RecSys Challenge 2015. In this dataset, click-stream data is collected from an e-commerce site. There are 7981580 sessions and 37483 items left after filtering out sessions of length 1 and items that appear less than 5 times. In YOOCHOOSE, we used the sessions of the next day for testing and filtered out clicks from the test set where the clicked items did not appear in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a header for YOOCHOOSE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Starting @ 2022-09-13 16:02:11.285843s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33003944it [05:03, 108893.82it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_data + 'yoochoose-clicks.dat', 'r') as f, open('../../yoochoose-clicks-withHeader.dat', 'w') as fn:\n",
    "    fn.write('sessionId,timestamp,itemId,category'+'\\n')\n",
    "    for line in f:\n",
    "        fn.write(line)\n",
    "\n",
    "dataset = '../../yoochoose-clicks-withHeader.dat'\n",
    "\n",
    "print(\"-- Starting @ %ss\" % datetime.datetime.now())\n",
    "with open(dataset, \"r\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    sess_clicks = {}\n",
    "    sess_date = {}\n",
    "    ctr = 0\n",
    "    curid = -1\n",
    "    curdate = None\n",
    "    for data in tqdm(reader):\n",
    "        sessid = data['sessionId']\n",
    "        if curdate and not curid == sessid:\n",
    "            date = time.mktime(time.strptime(curdate[:19], '%Y-%m-%dT%H:%M:%S'))\n",
    "            sess_date[curid] = date\n",
    "        curid = sessid\n",
    "        item = data['itemId']\n",
    "        curdate = data['timestamp']\n",
    "\n",
    "        if sessid in sess_clicks:\n",
    "            sess_clicks[sessid] += [item]\n",
    "        else:\n",
    "            sess_clicks[sessid] = [item]\n",
    "        ctr += 1\n",
    "    date = ''\n",
    "    date = time.mktime(time.strptime(curdate[:19], '%Y-%m-%dT%H:%M:%S'))\n",
    "    sess_date[curid] = date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out sessions with length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in list(sess_clicks):\n",
    "    if len(sess_clicks[s]) == 1:\n",
    "        del sess_clicks[s]\n",
    "        del sess_date[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of times each item appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_counts = {}\n",
    "for s in sess_clicks:\n",
    "    seq = sess_clicks[s]\n",
    "    for iid in seq:\n",
    "        if iid in iid_counts:\n",
    "            iid_counts[iid] += 1\n",
    "        else:\n",
    "            iid_counts[iid] = 1\n",
    "\n",
    "sorted_counts = sorted(iid_counts.items(), key=operator.itemgetter(1))\n",
    "\n",
    "length = len(sess_clicks)\n",
    "for s in list(sess_clicks):\n",
    "    curseq = sess_clicks[s]\n",
    "    filseq = list(filter(lambda i: iid_counts[i] >= 5, curseq))\n",
    "    if len(filseq) < 2:\n",
    "        del sess_clicks[s]\n",
    "        del sess_date[s]\n",
    "    else:\n",
    "        sess_clicks[s] = filseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split out test set based on dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting date 1411973999.0\n"
     ]
    }
   ],
   "source": [
    "dates = list(sess_date.items())\n",
    "maxdate = dates[0][1]\n",
    "\n",
    "for _, date in dates:\n",
    "    if maxdate < date:\n",
    "        maxdate = date\n",
    "\n",
    "# 7 days for test\n",
    "splitdate = maxdate - 86400 * 1  # the number of seconds for a day：86400\n",
    "\n",
    "\n",
    "print('Splitting date', splitdate)\n",
    "tra_sess = filter(lambda x: x[1] < splitdate, dates)\n",
    "tes_sess = filter(lambda x: x[1] > splitdate, dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort sessions by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7966257\n",
      "15324\n",
      "[('171168', 1396335632.0), ('345618', 1396335675.0), ('263073', 1396335702.0)]\n",
      "[('11532683', 1411974053.0), ('11464959', 1411974071.0), ('11296119', 1411974095.0)]\n",
      "-- Splitting train set and test set @ 2022-09-13 16:08:12.520311s\n"
     ]
    }
   ],
   "source": [
    "tra_sess = sorted(tra_sess, key=operator.itemgetter(1))     # [(sessionId, timestamp), (), ]\n",
    "tes_sess = sorted(tes_sess, key=operator.itemgetter(1))     # [(sessionId, timestamp), (), ]\n",
    "print(len(tra_sess))    # 186670    # 7966257\n",
    "print(len(tes_sess))    # 15979     # 15324\n",
    "print(tra_sess[:3])\n",
    "print(tes_sess[:3])\n",
    "print(\"-- Splitting train set and test set @ %ss\" % datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert training sessions to sequences and renumber items to start from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict = {}\n",
    "\n",
    "def obtian_tra():\n",
    "    train_ids = []\n",
    "    train_seqs = []\n",
    "    train_dates = []\n",
    "    item_ctr = 1\n",
    "    for s, date in tra_sess:\n",
    "        seq = sess_clicks[s]\n",
    "        outseq = []\n",
    "        for i in seq:\n",
    "            if i in item_dict:\n",
    "                outseq += [item_dict[i]]\n",
    "            else:\n",
    "                outseq += [item_ctr]\n",
    "                item_dict[i] = item_ctr\n",
    "                item_ctr += 1\n",
    "        if len(outseq) < 2:  # Doesn't occur\n",
    "            continue\n",
    "        train_ids += [s]\n",
    "        train_dates += [date]\n",
    "        train_seqs += [outseq]\n",
    "    print(item_ctr)     # 43098, 37484\n",
    "    return train_ids, train_dates, train_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert test sessions to sequences, ignoring items that do not appear in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtian_tes():\n",
    "    test_ids = []\n",
    "    test_seqs = []\n",
    "    test_dates = []\n",
    "    for s, date in tes_sess:\n",
    "        seq = sess_clicks[s]\n",
    "        outseq = []\n",
    "        for i in seq:\n",
    "            if i in item_dict:\n",
    "                outseq += [item_dict[i]]\n",
    "        if len(outseq) < 2:\n",
    "            continue\n",
    "        test_ids += [s]\n",
    "        test_dates += [date]\n",
    "        test_seqs += [outseq]\n",
    "    return test_ids, test_dates, test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37484\n"
     ]
    }
   ],
   "source": [
    "tra_ids, tra_dates, tra_seqs = obtian_tra()\n",
    "tes_ids, tes_dates, tes_seqs = obtian_tes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since NARM was not trained in a session-parallel manner, a sequence splitting preprocess is required. For the input session [x1, x2, ..., xn−1, xn], we generated the sequences and labels ([x1],V(x2), ([x1, x2],V(x3), ..., ([x1, x2, ..., xn−1],V (xn)) for training on YOOCHOOSE. The corresponding label V(xi) represents the last click in the current session. Due to the size of YOOCHOOSE, we sorted the YOOCHOOSE training sequences by time and reported the results for the model trained on more recent fractions 1/64 and 1/4 of training sequences. Since the model is trained on more recent fractions, some items from the test set will not appear in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seqs(iseqs, idates):\n",
    "    out_seqs = []\n",
    "    out_dates = []\n",
    "    labs = []\n",
    "    ids = []\n",
    "    for id, seq, date in zip(range(len(iseqs)), iseqs, idates):\n",
    "        for i in range(1, len(seq)):\n",
    "            tar = seq[-i]\n",
    "            labs += [tar]\n",
    "            out_seqs += [seq[:-i]]\n",
    "            out_dates += [date]\n",
    "            ids += [id]\n",
    "    return out_seqs, out_dates, labs, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZDd1w2AQjS7",
    "outputId": "fdd40158-edeb-427b-eedc-3d1c359e59f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23670982\n",
      "55898\n",
      "[[1], [3], [5, 5]] [1396335632.0, 1396335675.0, 1396335702.0] [2, 4, 5]\n",
      "[[33611, 37169, 6409], [33611, 37169], [33611]] [1411974053.0, 1411974053.0, 1411974053.0] [33128, 6409, 37169]\n",
      "avg length:  3.9727042800167034\n",
      "5917745\n",
      "369859\n"
     ]
    }
   ],
   "source": [
    "tr_seqs, tr_dates, tr_labs, tr_ids = process_seqs(tra_seqs, tra_dates)\n",
    "te_seqs, te_dates, te_labs, te_ids = process_seqs(tes_seqs, tes_dates)\n",
    "tra = (tr_seqs, tr_labs)\n",
    "tes = (te_seqs, te_labs)\n",
    "print(len(tr_seqs))\n",
    "print(len(te_seqs))\n",
    "print(tr_seqs[:3], tr_dates[:3], tr_labs[:3])\n",
    "print(te_seqs[:3], te_dates[:3], te_labs[:3])\n",
    "\n",
    "all = 0\n",
    "\n",
    "for seq in tra_seqs:\n",
    "    all += len(seq)\n",
    "for seq in tes_seqs:\n",
    "    all += len(seq)\n",
    "print('avg length: ', all/(len(tra_seqs) + len(tes_seqs) * 1.0))\n",
    "\n",
    "if not os.path.exists('../../yoochoose'):\n",
    "    os.makedirs('../../yoochoose')\n",
    "if not os.path.exists('../../yoochoose1_4'):\n",
    "    os.makedirs('../../yoochoose1_4')\n",
    "if not os.path.exists('../../yoochoose1_64'):\n",
    "    os.makedirs('../../yoochoose1_64')\n",
    "\n",
    "pickle.dump(tes, open('../../yoochoose/test.txt', 'wb'))\n",
    "pickle.dump(tes, open('../../yoochoose1_4/test.txt', 'wb'))\n",
    "pickle.dump(tes, open('../../yoochoose1_64/test.txt', 'wb'))\n",
    "\n",
    "split4, split64 = int(len(tr_seqs) / 4), int(len(tr_seqs) / 64)\n",
    "print(len(tr_seqs[-split4:]))\n",
    "print(len(tr_seqs[-split64:]))\n",
    "\n",
    "tra4, tra64 = (tr_seqs[-split4:], tr_labs[-split4:]), (tr_seqs[-split64:], tr_labs[-split64:])\n",
    "seq4, seq64 = tra_seqs[tr_ids[-split4]:], tra_seqs[tr_ids[-split64]:]\n",
    "\n",
    "pickle.dump((tr_seqs, tr_labs), open('../../yoochoose/train.txt', 'wb'))\n",
    "pickle.dump(tra_seqs, open('../../yoochoose/all_train_seq.txt', 'wb'))\n",
    "\n",
    "pickle.dump(tra4, open('../../yoochoose1_4/train.txt', 'wb'))\n",
    "pickle.dump(seq4, open('../../yoochoose1_4/all_train_seq.txt', 'wb'))\n",
    "\n",
    "pickle.dump(tra64, open('../../yoochoose1_64/train.txt', 'wb'))\n",
    "pickle.dump(seq64, open('../../yoochoose1_64/all_train_seq.txt', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qZf6ffKPQjX7"
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"This function will be used to pad the sessions to max length\n",
    "       in the batch and transpose the batch from \n",
    "       batch_size x max_seq_len to max_seq_len x batch_size.\n",
    "       It will return padded vectors, labels and lengths of each session (before padding)\n",
    "       It will be used in the Dataloader\n",
    "    \"\"\"\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    lens = [len(sess) for sess, label in data]\n",
    "    labels = []\n",
    "    padded_sesss = torch.zeros(len(data), max(lens)).long()\n",
    "    for i, (sess, label) in enumerate(data):\n",
    "        padded_sesss[i,:lens[i]] = torch.LongTensor(sess)\n",
    "        labels.append(label)\n",
    "    \n",
    "    padded_sesss = padded_sesss.transpose(0,1)\n",
    "    return padded_sesss, torch.tensor(labels).long(), lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nRCDev45fiuL"
   },
   "outputs": [],
   "source": [
    "def load_data(root, valid_portion=0.1, maxlen=19, sort_by_len=False):\n",
    "    '''Loads the dataset\n",
    "\n",
    "    :type path: String\n",
    "    :param path: The path to the dataset (here RSC2015)\n",
    "    :type n_items: int\n",
    "    :param n_items: The number of items.\n",
    "    :type valid_portion: float\n",
    "    :param valid_portion: The proportion of the full train set used for\n",
    "        the validation set.\n",
    "    :type maxlen: None or positive int\n",
    "    :param maxlen: the max sequence length we use in the train/valid set.\n",
    "    :type sort_by_len: bool\n",
    "    :name sort_by_len: Sort by the sequence length for the train,\n",
    "        valid and test set. This allow faster execution as it cause\n",
    "        less padding per minibatch. Another mechanism must be used to\n",
    "        shuffle the train set at each epoch.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Load the dataset\n",
    "    path_train_data = root + 'train.txt'\n",
    "    path_test_data = root + 'test.txt'\n",
    "    with open(path_train_data, 'rb') as f1:\n",
    "        train_set = pickle.load(f1)\n",
    "\n",
    "    with open(path_test_data, 'rb') as f2:\n",
    "        test_set = pickle.load(f2)\n",
    "\n",
    "    if maxlen:\n",
    "        new_train_set_x = []\n",
    "        new_train_set_y = []\n",
    "        for x, y in zip(train_set[0], train_set[1]):\n",
    "            if len(x) < maxlen:\n",
    "                new_train_set_x.append(x)\n",
    "                new_train_set_y.append(y)\n",
    "            else:\n",
    "                new_train_set_x.append(x[:maxlen])\n",
    "                new_train_set_y.append(y)\n",
    "        train_set = (new_train_set_x, new_train_set_y)\n",
    "        del new_train_set_x, new_train_set_y\n",
    "\n",
    "        new_test_set_x = []\n",
    "        new_test_set_y = []\n",
    "        for xx, yy in zip(test_set[0], test_set[1]):\n",
    "            if len(xx) < maxlen:\n",
    "                new_test_set_x.append(xx)\n",
    "                new_test_set_y.append(yy)\n",
    "            else:\n",
    "                new_test_set_x.append(xx[:maxlen])\n",
    "                new_test_set_y.append(yy)\n",
    "        test_set = (new_test_set_x, new_test_set_y)\n",
    "        del new_test_set_x, new_test_set_y\n",
    "\n",
    "    # split training set into validation set\n",
    "    train_set_x, train_set_y = train_set\n",
    "    n_samples = len(train_set_x)\n",
    "    sidx = np.arange(n_samples, dtype='int32')\n",
    "    np.random.shuffle(sidx)\n",
    "    n_train = int(np.round(n_samples * (1. - valid_portion)))\n",
    "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
    "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
    "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
    "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
    "\n",
    "    (test_set_x, test_set_y) = test_set\n",
    "\n",
    "    def len_argsort(seq):\n",
    "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
    "\n",
    "    if sort_by_len:\n",
    "        sorted_index = len_argsort(test_set_x)\n",
    "        test_set_x = [test_set_x[i] for i in sorted_index]\n",
    "        test_set_y = [test_set_y[i] for i in sorted_index]\n",
    "\n",
    "        sorted_index = len_argsort(valid_set_x)\n",
    "        valid_set_x = [valid_set_x[i] for i in sorted_index]\n",
    "        valid_set_y = [valid_set_y[i] for i in sorted_index]\n",
    "\n",
    "    train = (train_set_x, train_set_y)\n",
    "    valid = (valid_set_x, valid_set_y)\n",
    "    test = (test_set_x, test_set_y)\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "\n",
    "class RecSysDataset(Dataset):\n",
    "    \"\"\"define the pytorch Dataset class for yoochoose datasets.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        print('-'*50)\n",
    "        print('Dataset info:')\n",
    "        print('Number of sessions: {}'.format(len(data[0])))\n",
    "        print('-'*50)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        session_items = self.data[0][index]\n",
    "        target_item = self.data[1][index]\n",
    "        return session_items, target_item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<style>\n",
    "img {\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://user-images.githubusercontent.com/34673511/188940697-319e650c-bfe8-4113-9d7c-a236fde7c8f2.png\" alt=\"\" style=\"width:100%;>\n",
    "<figcaption align = \"center\"></figcaption>\n",
    "</figure>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global encoder and the local encoder in NARM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<style>\n",
    "img {\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://user-images.githubusercontent.com/34673511/188919605-ab0abfb5-cdb1-4579-9189-b4a4f75bcd7e.PNG\" alt=\"\" style=\"width:80%;>\n",
    "<figcaption align = \"center\"></figcaption>\n",
    "</figure>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphical model of NARM, where the session feature $c_{t}$ is represented by the concatenation of the vectors $c_{t}^{g}$ and $c_{t}^{l}$. Note that $h_{t}^{g}$ and $h_{t}^{l}$ have different roles, but the same values. The last hidden state of the global encoder $h_{t}^{g}$ plays a role in the encoding of the entire input clicks, while the last hidden state of the local encoder $h_{t}^{l}$ calculates attention weights based on previous hidden states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GL__SzL_fcqP"
   },
   "outputs": [],
   "source": [
    "class NARM(nn.Module):\n",
    "    \"\"\"Neural Attentive Session Based Recommendation Model Class\n",
    "\n",
    "    Args:\n",
    "        n_items(int): the number of items\n",
    "        hidden_size(int): the hidden size of gru\n",
    "        embedding_dim(int): the dimension of item embedding\n",
    "        batch_size(int): \n",
    "        n_layers(int): the number of gru layers\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_items, hidden_size, embedding_dim, batch_size, n_layers = 1):\n",
    "        super(NARM, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.emb = nn.Embedding(self.n_items, self.embedding_dim, padding_idx = 0)\n",
    "        self.emb_dropout = nn.Dropout(0.25)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.hidden_size, self.n_layers)\n",
    "        self.a_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.a_2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.v_t = nn.Linear(self.hidden_size, 1, bias=False)\n",
    "        self.ct_dropout = nn.Dropout(0.5)\n",
    "        self.b = nn.Linear(self.embedding_dim, 2 * self.hidden_size, bias=False)\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def forward(self, seq, lengths):\n",
    "        hidden = self.init_hidden(seq.size(1))\n",
    "        embs = self.emb_dropout(self.emb(seq))\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, hidden = self.gru(embs, hidden)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)\n",
    "\n",
    "        # fetch the last hidden state of last timestamp\n",
    "        ht = hidden[-1]\n",
    "        gru_out = gru_out.permute(1, 0, 2)\n",
    "\n",
    "        c_global = ht\n",
    "        q1 = self.a_1(gru_out.contiguous().view(-1, self.hidden_size)).view(gru_out.size())  \n",
    "        q2 = self.a_2(ht)\n",
    "\n",
    "        mask = torch.where(seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device))\n",
    "        q2_expand = q2.unsqueeze(1).expand_as(q1)\n",
    "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand\n",
    "\n",
    "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size())\n",
    "        c_local = torch.sum(alpha.unsqueeze(2).expand_as(gru_out) * gru_out, 1)\n",
    "\n",
    "        c_t = torch.cat([c_local, c_global], 1)\n",
    "        c_t = self.ct_dropout(c_t)\n",
    "        \n",
    "        item_embs = self.emb(torch.arange(self.n_items).to(self.device))\n",
    "        scores = torch.matmul(c_t, self.b(item_embs).permute(1, 0))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((self.n_layers, batch_size, self.hidden_size), requires_grad=True).to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the method with the following metrics:\n",
    "\n",
    "- **Recall at K (Recall@K)**: It is the proportion of cases when the desired item is amongst the top-k items in all test cases (a test example receives a score of 1 when the nth item appears, and 0 otherwise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<style>\n",
    "img {\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*4idLDQc9FiyCMXy8Ck-LSA.png\" alt=\"\" width=\"300\" height=\"200\";>\n",
    "<figcaption align = \"center\" >\n",
    "</figure>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Mean Reciprocal Rank at K (MRR@K)**: For all test cases, it is the average of reciprocal ranks of the desire items. The reciprocal rank is set to zero if the rank is larger than k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<style>\n",
    "img {\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://miro.medium.com/max/872/1*Yz8One3GN-vJfQxy6n2rAw.png\" alt=\"\" width=\"220\" height=\"\">\n",
    "<figcaption align = \"center\" >\n",
    "</figure>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "v6-e3dljQjVd"
   },
   "outputs": [],
   "source": [
    "def get_recall(indices, targets):\n",
    "    \"\"\"\n",
    "    Calculates the recall score for the given predictions and targets\n",
    "\n",
    "    Args:\n",
    "        indices (Bxk): torch.LongTensor. top-k indices predicted by the model.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "\n",
    "    Returns:\n",
    "        recall (float): the recall score\n",
    "    \"\"\"\n",
    "\n",
    "    targets = targets.view(-1, 1).expand_as(indices)\n",
    "    hits = (targets == indices).nonzero()\n",
    "    if len(hits) == 0:\n",
    "        return 0\n",
    "    n_hits = (targets == indices).nonzero()[:, :-1].size(0)\n",
    "    recall = float(n_hits) / targets.size(0)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def get_mrr(indices, targets):\n",
    "    \"\"\"\n",
    "    Calculates the MRR score for the given predictions and targets\n",
    "    Args:\n",
    "        indices (Bxk): torch.LongTensor. top-k indices predicted by the model.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "\n",
    "    Returns:\n",
    "        mrr (float): the mrr score\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = targets.view(-1, 1)\n",
    "    targets = tmp.expand_as(indices)\n",
    "    hits = (targets == indices).nonzero()\n",
    "    ranks = hits[:, -1] + 1\n",
    "    ranks = ranks.float()\n",
    "    rranks = torch.reciprocal(ranks)\n",
    "    mrr = torch.sum(rranks).data / targets.size(0)\n",
    "    return mrr.item()\n",
    "\n",
    "\n",
    "def evaluate(indices, targets, k=20):\n",
    "    \"\"\"\n",
    "    Evaluates the model using Recall@K, MRR@K scores.\n",
    "\n",
    "    Args:\n",
    "        logits (B,C): torch.LongTensor. The predicted logit for the next items.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "\n",
    "    Returns:\n",
    "        recall (float): the recall score\n",
    "        mrr (float): the mrr score\n",
    "    \"\"\"\n",
    "    _, indices = torch.topk(indices, k, -1)\n",
    "    recall = get_recall(indices, targets)\n",
    "    mrr = get_mrr(indices, targets)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tFPdbE8QQjaO"
   },
   "outputs": [],
   "source": [
    "def trainForEpoch(train_loader, model, optimizer, epoch, num_epochs, criterion, log_aggr=1):\n",
    "    model.train()\n",
    "\n",
    "    sum_epoch_loss = 0\n",
    "\n",
    "    start = time.time()\n",
    "    for i, (seq, target, lens) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        seq = seq.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(seq, lens)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        loss_val = loss.item()\n",
    "        sum_epoch_loss += loss_val\n",
    "\n",
    "        iter_num = epoch * len(train_loader) + i + 1\n",
    "\n",
    "        if i % log_aggr == 0:\n",
    "            print('[TRAIN] epoch %d/%d batch loss: %.4f (avg %.4f) (%.2f im/s)'\n",
    "                % (epoch, num_epochs, loss_val, sum_epoch_loss / (i + 1),\n",
    "                  len(seq) / (time.time() - start)))\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "\n",
    "def validate(valid_loader, model):\n",
    "    model.eval()\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "    with torch.no_grad():\n",
    "        for seq, target, lens in tqdm(valid_loader):\n",
    "            seq = seq.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs = model(seq, lens)\n",
    "            logits = F.softmax(outputs, dim = 1)\n",
    "            recall, mrr = evaluate(logits, target, k = topk)\n",
    "            recalls.append(recall)\n",
    "            mrrs.append(mrr)\n",
    "    \n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_mrr = np.mean(mrrs)\n",
    "    return mean_recall, mean_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on all training sequences of YOOCHOOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MvT5Xp5Hh57c"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"../../yoochoose/\"\n",
    "valid_portion = 0.1\n",
    "batch_size = 512\n",
    "hidden_size = 100\n",
    "embed_dim = 50\n",
    "epoch = 10\n",
    "lr = 0.001\n",
    "lr_dc = 0.1\n",
    "lr_dc_step = 80\n",
    "topk = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "O8mohXPThztx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 21303884\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 2367098\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "train, valid, test = load_data(dataset_path, valid_portion=valid_portion)\n",
    "\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "n_items = 37484\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NARM(n_items, hidden_size, embed_dim, batch_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size = lr_dc_step, gamma = lr_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epoch + 1)):\n",
    "    # train for one epoch\n",
    "    scheduler.step(epoch = epoch)\n",
    "    trainForEpoch(train_loader, model, optimizer, epoch, epoch, criterion, log_aggr = 200)\n",
    "\n",
    "    recall, mrr = validate(valid_loader, model)\n",
    "    print('Epoch {} validation: Recall@{}: {:.4f}, MRR@{}: {:.4f} \\n'.format(epoch, topk, recall, topk, mrr))\n",
    "\n",
    "    # store best loss and save a model checkpoint\n",
    "    ckpt_dict = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(ckpt_dict, '../../latest_checkpoint_yoochoose.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gl6L2ZpQjgI",
    "outputId": "3cef2f62-c971-46dc-9f6f-2134999f5182"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:02<00:00, 41.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.6726, MRR@20: 0.2774\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load('/ssd003/projects/aieng/public/recsys_ckpts/latest_checkpoint_yoochoose.pth')\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall, mrr = validate(test_loader, model)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(topk, recall, topk, mrr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Result Compared to baselines </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Methods/Metrics      | Recall@20 | MRR@20     |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| POP      | 0.0050       | 0.0012   |\n",
    "| S-POP   | 0.2672        | 0.1775      |\n",
    "| BPR-MF   | 0.2574        | 0.0618      |\n",
    "| Item-KNN      | 0.5065       | 0.2048   |\n",
    "| GRU4Rec   | **0.719952**        | **0.316040**      |\n",
    "| **NARM**   | 0.6726        | 0.2774      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxVa5YPJWQXH"
   },
   "source": [
    "### Train on the 1/4 of training sequences of YOOCHOOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qOXpSkoqGl7f"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"../../yoochoose1_4/\"\n",
    "valid_portion = 0.1\n",
    "batch_size = 512\n",
    "hidden_size = 100\n",
    "embed_dim = 50\n",
    "epoch = 100\n",
    "lr = 0.001\n",
    "lr_dc = 0.1\n",
    "lr_dc_step = 80\n",
    "topk = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpBf63jrRO8s",
    "outputId": "9340c320-12c6-4bf3-a41a-3181ca01f59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 5325970\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 591775\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "train, valid, test = load_data(dataset_path, valid_portion=valid_portion)\n",
    "\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "n_items = 37484\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NARM(n_items, hidden_size, embed_dim, batch_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size = lr_dc_step, gamma = lr_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epoch + 1)):\n",
    "    # train for one epoch\n",
    "    scheduler.step(epoch = epoch)\n",
    "    trainForEpoch(train_loader, model, optimizer, epoch, epoch, criterion, log_aggr = 200)\n",
    "\n",
    "    recall, mrr = validate(valid_loader, model)\n",
    "    print('Epoch {} validation: Recall@{}: {:.4f}, MRR@{}: {:.4f} \\n'.format(epoch, topk, recall, topk, mrr))\n",
    "\n",
    "    # store best loss and save a model checkpoint\n",
    "    ckpt_dict = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(ckpt_dict, '../../latest_checkpoint_yoochoose1_4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qihOPK-uRO--"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:01<00:00, 56.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.7042, MRR@20: 0.2994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load('/ssd003/projects/aieng/public/recsys_ckpts/latest_checkpoint_yoochoose1_4.pth')\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall, mrr = validate(test_loader, model)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(topk, recall, topk, mrr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Result Compared to baselines </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Methods/Metrics      | Recall@20 | MRR@20     |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| POP      | 0.133       | 0.030   |\n",
    "| S-POP   |  0.2708         | 0.1775      |\n",
    "| BPR-MF   |  0.340        | 0.2170      |\n",
    "| Item-KNN      | 0.5231        | 0.157     |\n",
    "| GRU4Rec   | 0.5953         | 0.2260      |\n",
    "| **NARM**   | **0.7042**         | **0.2994**      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8HEYP0aWTSG"
   },
   "source": [
    "### Train on the 1/64 of training sequences of YOOCHOOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4YQnxH3VRYYm"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"../../yoochoose1_64/\"\n",
    "valid_portion = 0.1\n",
    "batch_size = 512\n",
    "hidden_size = 100\n",
    "embed_dim = 50\n",
    "epoch = 100\n",
    "lr = 0.001\n",
    "lr_dc = 0.1\n",
    "lr_dc_step = 80\n",
    "topk = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kHYMLKl5RWnd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 332873\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 36986\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "train, valid, test = load_data(dataset_path, valid_portion=valid_portion)\n",
    "\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "n_items = 37484\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NARM(n_items, hidden_size, embed_dim, batch_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size = lr_dc_step, gamma = lr_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epoch + 1)):\n",
    "    # train for one epoch\n",
    "    scheduler.step(epoch = epoch)\n",
    "    trainForEpoch(train_loader, model, optimizer, epoch, epoch, criterion, log_aggr = 200)\n",
    "\n",
    "    recall, mrr = validate(valid_loader, model)\n",
    "    print('Epoch {} validation: Recall@{}: {:.4f}, MRR@{}: {:.4f} \\n'.format(epoch, topk, recall, topk, mrr))\n",
    "\n",
    "    # store best loss and save a model checkpoint\n",
    "    ckpt_dict = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(ckpt_dict, '../../latest_checkpoint_yoochoose1_64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WllLCHHuRWp0",
    "outputId": "ba575d2e-b531-4cc6-c79a-e91d3aac9cbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:01<00:00, 58.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.6888, MRR@20: 0.2936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load('/ssd003/projects/aieng/public/recsys_ckpts/latest_checkpoint_yoochoose1_64.pth')\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall, mrr = validate(test_loader, model)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(topk, recall, topk, mrr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Result Compared to baselines </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Methods/Metrics      | Recall@20 | MRR@20     |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| POP      |  0.671        | 0.165   |\n",
    "| S-POP   |   0.3044          | 0.1835      |\n",
    "| BPR-MF   |  0.340        | 0.2170      |\n",
    "| Item-KNN      |  0.5160         | 0.2181     |\n",
    "| GRU4Rec   |  0.6064          | 0.2289      |\n",
    "| **NARM**   | **0.6888**         | **0.2936**      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHx4N6riEe7v"
   },
   "source": [
    "1. <a href=\"https://arxiv.org/pdf/1711.04725.pdf\" title=\"Neural Attenntive Session-based Recommendation\">Li, Jing, et al. Neural Attenntive Session-based Recommendation.</a>\n",
    "2. https://github.com/Wang-Shuo/Neural-Attentive-Session-Based-Recommendation-PyTorch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Demo 2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
