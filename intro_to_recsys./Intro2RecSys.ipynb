{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob70DFdS2ErB"
   },
   "source": [
    "In this notebook, you will obtain an introductory acquiantiance to baseline recommendation algorithms and evaluation methods.\n",
    "The recommendation dataset we will be using is from a collection called MovieLens, which contains usersâ€™ movie ratings and is popular for implementing and testing recommender systems. The specific dataset we will be using for this lab is MovieLens 100K Dataset which contains 100,000 movie ratings from 943 users and a selection of 1682 movies. In recommendation research works, usually a larger version of this dataset, MovieLens 20M is used instead.\n",
    "First, we import the necessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50nqYwXN1uBm",
    "outputId": "5a858e0c-616f-4a46-deaf-2fe8b45d3930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=7b9ed861fd2531f478b8d9a7a8f6b2cd3028272dcf3478dc0a2ba2aecc9a0624\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "!pip install wget\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKROKg9u2twB"
   },
   "source": [
    "Downloading the dataset and have a glance on its statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWLqiqSR2s0n"
   },
   "outputs": [],
   "source": [
    "MOVIELENS_DIR = \"/ssd003/projects/aieng/public/recsys_datasets/movielens/ml-100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLDpkVyC24KH"
   },
   "outputs": [],
   "source": [
    "!ls {MOVIELENS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qz64DO-m26E8"
   },
   "outputs": [],
   "source": [
    "def getData(folder_path, file_name):\n",
    "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q__VHTbH29N4"
   },
   "outputs": [],
   "source": [
    "rating_df = getData(MOVIELENS_DIR, 'u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8l_HNXO3IkK"
   },
   "outputs": [],
   "source": [
    "rating_df_train = getData(MOVIELENS_DIR, 'u1.base')\n",
    "rating_df_test = getData(MOVIELENS_DIR, 'u1.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgqTmmXd3Kfa"
   },
   "outputs": [],
   "source": [
    "rating_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_hJF9Q63MXq"
   },
   "outputs": [],
   "source": [
    "rating_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PHkQpHo3OeO"
   },
   "outputs": [],
   "source": [
    "print(\"Number of users in rating df:\", len(rating_df.userID.unique()))\n",
    "print(\"Number of items in rating df:\", len(rating_df.itemID.unique()))\n",
    "print(\"Number of users in train df:\", len(rating_df_train.userID.unique()))\n",
    "print(\"Number of items in train df:\", len(rating_df_train.itemID.unique()))\n",
    "print(\"Number of users in test df:\", len(rating_df_test.userID.unique()))\n",
    "print(\"Number of items in test df:\", len(rating_df_test.itemID.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8nHKOrP34nS"
   },
   "source": [
    "Data inrecommendation systems is usually encoded as dataframe with three or more columns: (user, item, rating, additional meta-data if present). Here, we implement the function dataPreprocessor that takes the data frame, total number of users, total number of items and outputs a user-item utility matrix as demonstrated in the tutorial. See the function comments for more guidance. The following experiments will all use dataPreprocessor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yblFn2j64P_m"
   },
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items):\n",
    "    \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
    "            num_row: int. number of users\n",
    "            num_col: int. number of items\n",
    "            \n",
    "        OUTPUT:\n",
    "            matrix: 2D numpy array. \n",
    "            \n",
    "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
    "            \n",
    "        NOTE 2: data can have more columns, but your function should ignore \n",
    "              additional columns.\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
    "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
    "      matrix[userID-1, itemID-1] = rating\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muu42E4T4g_G"
   },
   "source": [
    "Two baseline recommender models are implemented in this class. The first one, we make predictions by taking the average of ratings of the user. In popularity, we use the popularity of items for making recommendations (recommending the most popular items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFA81IgN4fZ5"
   },
   "outputs": [],
   "source": [
    "class BaseLineRecSys(object):\n",
    "    def __init__(self, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            method: string. From ['popularity','useraverage']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.method_name\n",
    "        \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'popularity': self.popularity,\n",
    "            'useraverage': self.useraverage,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def useraverage(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
    "        \"\"\"\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "\n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "          if rating==0:\n",
    "            userVector = train_matrix[user, :]\n",
    "            ratedItems = userVector[userVector.nonzero()]\n",
    "            if ratedItems.size == 0:\n",
    "              itemAvg=0\n",
    "            else:\n",
    "              itemAvg= ratedItems.mean()\n",
    "            predictionMatrix[user, item] = itemAvg\n",
    "          #if (user % 100 == 0 and item == 1):\n",
    "          #  print (\"calculated %d users\" % (user,))\n",
    "        return predictionMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def popularity(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
    "        \"\"\"\n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "\n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "        itemPopularity = np.zeros((num_items))\n",
    "        for item in range(num_items):\n",
    "          numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
    "          numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
    "          if numOfUsersRated == 0:\n",
    "            itemPopularity[item] = 0\n",
    "          else:\n",
    "            itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "          if rating==0:\n",
    "            predictionMatrix[user, item] = itemPopularity[item]\n",
    "         # if (user % 100 == 0 and item == 1):\n",
    "         #   print (\"calculated %d users\" % (user,))\n",
    "\n",
    "        return predictionMatrix    \n",
    "    \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        self.__model = self.method(train_matrix, num_users, num_items)\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "            \n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        self.__model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6tRkwrH5qKR"
   },
   "outputs": [],
   "source": [
    "popularity_recsys = BaseLineRecSys('popularity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7hO98gP5qp3"
   },
   "outputs": [],
   "source": [
    "popularity_recsys.predict_all(rating_df_train,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRfjtrfH5sMi"
   },
   "outputs": [],
   "source": [
    "x = popularity_recsys.getModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdK5wblR5wIo"
   },
   "outputs": [],
   "source": [
    "np.all(x<=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWuZ4DfO5yal"
   },
   "outputs": [],
   "source": [
    "rating_df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_SxixpI50jJ"
   },
   "outputs": [],
   "source": [
    "popularity_recsys.evaluate_test(rating_df_test,copy=True).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UT2_vpDb52ay"
   },
   "outputs": [],
   "source": [
    "average_user_rating_recsys = BaseLineRecSys('useraverage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPMj7kMB54BZ"
   },
   "outputs": [],
   "source": [
    "average_user_rating_recsys.predict_all(rating_df_train, len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_b90YKGa559O"
   },
   "outputs": [],
   "source": [
    "average_user_rating_recsys.getModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvjTMqS_58H0"
   },
   "outputs": [],
   "source": [
    "average_user_rating_recsys.evaluate_test(rating_df_test,copy=True).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klZWezoN5XLF"
   },
   "source": [
    "In class SimBasedRecSys, there are three similarity measurement functions (cosine, eu- clidean, Manhattan Distance). These metrics will be used to measure user-user and item-item similarities in collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gp6QZCfj6AKk"
   },
   "outputs": [],
   "source": [
    "class SimBasedRecSys(object):\n",
    "\n",
    "    def __init__(self, base, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
    "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.base = base\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.base+'-'+self.method_name\n",
    "    \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'cosine': self.cosine,\n",
    "            'euclidean': self.euclidean,\n",
    "            'somethingelse': self.somethingelse,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine(matrix):\n",
    "        \"\"\"\n",
    "            cosine similarity\n",
    "        \"\"\"\n",
    "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean(matrix):\n",
    "        \"\"\"\n",
    "            euclidean similarity\n",
    "        \"\"\"\n",
    " \n",
    "        similarity_matrix = 1 / (pairwise_distances(matrix, metric='euclidean')+1)  \n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def somethingelse(matrix):\n",
    "        \"\"\"\n",
    "            manhattan\n",
    "        \"\"\"\n",
    "        similarity_matrix = 1 /(pairwise_distances(matrix, metric='l1')+1)      \n",
    "        return similarity_matrix\n",
    "        \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_row: scalar. number of users\n",
    "                num_col: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method assigns the result to self.__model\n",
    "            \n",
    "            NOTES:\n",
    "                self.__model should contain predictions for *all* user and items\n",
    "                (don't worry about predicting for observed (user,item) pairs,\n",
    "                 since we won't be using these predictions in the evaluation)\n",
    "                (see code in for an efficient vectorized example)\n",
    "        \"\"\"\n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        \n",
    "        if self.base == 'user':\n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            temp_matrix[train_matrix.nonzero()] = 1\n",
    "            uu_similarity=self.cosine(train_matrix)\n",
    "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
    "            useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "\n",
    "            \n",
    "        elif self.base == 'item':\n",
    "\n",
    "            train_matrix_item=np.transpose(train_matrix)\n",
    "            temp_matrix = np.zeros(train_matrix_item.shape)\n",
    "            temp_matrix[train_matrix_item.nonzero()] = 1\n",
    "            ii_similarity=self.cosine(train_matrix_item)\n",
    "            normalizer = np.matmul(ii_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(ii_similarity, train_matrix_item)/normalizer\n",
    "            temp_matrix[temp_matrix==0] = 1e-5\n",
    "            itemaverage = np.sum(train_matrix_item, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
    "            predictionMatrix=np.transpose(predictionMatrix)\n",
    "        else:\n",
    "            print('No other option available')\n",
    "        self.__model=predictionMatrix\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "                              \n",
    "            NOTE: 1. data can have more columns, but your function should ignore \n",
    "                  additional columns.\n",
    "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
    "                  if base == 'user' and method == 'cosine', \n",
    "                  then base-method == 'user-cosine'\n",
    "                  3. your predictions go to 'base-method' column\n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        self.__model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJX5z-zq6kbJ"
   },
   "outputs": [],
   "source": [
    "# Examples of how to call similarity functions.\n",
    "I = np.eye(3)\n",
    "SimBasedRecSys.cosine(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYoXsnFJ6nZL"
   },
   "outputs": [],
   "source": [
    "SimBasedRecSys.euclidean(I)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7MsFkYq6o8_"
   },
   "outputs": [],
   "source": [
    "SimBasedRecSys.somethingelse(I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAIzUW486ui8"
   },
   "source": [
    "##Collaborative Filtering\n",
    "We have implemented vectorized versions of collaborative filtering since loop-based versions will take excessively long to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Hm8bqFx69Qx"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cbsrIWs7fgS"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys.predict_all(rating_df_train,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgYtJFkL7hG0"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys.getModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2yxoIpj7i9W"
   },
   "outputs": [],
   "source": [
    "rating_df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gItg3byH7k8I"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys.evaluate_test(rating_df_test,copy=True).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8LZjPDJ7uUF"
   },
   "source": [
    "CrossValidation will be used to report comparative RMSE results (averages and confidence intervals) between user-user and item-item based collaborative filtering for cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLp65Sgo7sVu"
   },
   "outputs": [],
   "source": [
    "class CrossValidation(object):\n",
    "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(MOVIELENS_DIR)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "            'RPrecision': self.rprecision\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return float(sumPrecisions)/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRecalls)/countRecalls\n",
    "\n",
    "    def rprecision(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame.\n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet = self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRPs = 0\n",
    "        countRPs = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID, :]\n",
    "\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID, :]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            topK = nlargest(len(userTestVector), range(len(userVector)), userVector.take)\n",
    "            # Calculate recall\n",
    "            rp = float(len([item for item in topK if item in userTestVector])) / len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRPs += rp\n",
    "            countRPs += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRPs) / countRPs\n",
    "\n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4NHNV3Q759J"
   },
   "outputs": [],
   "source": [
    "# 1. gather your algorithms in previous steps.\n",
    "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
    "algorithm_instances = [user_cosine_recsys,\n",
    "                       item_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88y5o2K478oO"
   },
   "outputs": [],
   "source": [
    "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
    "# RMSE, P@K, RPrecision\n",
    "# Precision at K in this example\n",
    "cv_patk = CrossValidation('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0k4HpCI67-1Q"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Run CV by giving:\n",
    "#    1> algorithms just gathered\n",
    "#    2> number of users in the full dataset\n",
    "#    3> number of items in the full dataset\n",
    "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
    "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
    "cv_patk.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()),k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVGFq9658EEG"
   },
   "outputs": [],
   "source": [
    "all_ratings=rating_df_train.shape[0]\n",
    "avg_Ratings_peruser=all_ratings/len(rating_df.userID.unique())\n",
    "avg_Ratings_peritem=all_ratings/len(rating_df.itemID.unique())\n",
    "print(\"average ratings per user is:\"+str(avg_Ratings_peruser))\n",
    "print(\"average ratings per item is:\"+str(avg_Ratings_peritem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyw-71Xk8KSx"
   },
   "source": [
    "Considering the RMSE values, we see that the RMSE for the case that we use user-user cosine similarity is: 1.0173541216605808 and for item-item similarity it is: 1.020082900106248. We know that generally, item-item similarity is expected to provide better results since items attributes vary less that users' tastes. However, here we see that the user-user similarity has provided less RMSE. First of all, the amount of difference between the two is low and maybe by performing more accurate statistical tests, we see that the difference isn't statistically significant. By the way, we can ratiocinate this little difference by considering the average ratings per item and user which is provided above. We see that the average number of ratings per user is about double the average number of ratings per item. Therefore, we have more information about each user than we know about each item. So, measuring the similarity between users can be more informative and results in less RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeTZiPgB8MBY"
   },
   "source": [
    "##Performance Comparison\n",
    "Here, using the CrossValidation class, we compare all the recommmenders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TrBNIq58fCD"
   },
   "outputs": [],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
    "algorithm_instances = [popularity_recsys, \n",
    "                       average_user_rating_recsys, \n",
    "                       user_cosine_recsys,\n",
    "                       item_cosine_recsys]\n",
    "cv_patk_output=cv_patk.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()),k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M84BO-lX8jNO"
   },
   "outputs": [],
   "source": [
    "cv_rmse = CrossValidation('RMSE')\n",
    "cv_rmse_output=cv_rmse.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()),k=5)\n",
    "cv_ratk = CrossValidation('R@K')\n",
    "cv_ratk_output=cv_ratk.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()),k=5)\n",
    "cv_rprec = CrossValidation('RPrecision')\n",
    "cv_rprec_output=cv_rprec.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()),k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFRu7q5W8mxj"
   },
   "outputs": [],
   "source": [
    "output_dict={'item-cosine':['item-cosine',cv_patk_output['item-cosine'][1],cv_rmse_output['item-cosine'][1],cv_ratk_output['item-cosine'][1],cv_rprec_output['item-cosine'][1]],\n",
    "             'popularity':['popularity',cv_patk_output['popularity'][1],cv_rmse_output['popularity'][1],cv_ratk_output['popularity'][1],cv_rprec_output['popularity'][1]],\n",
    "             'user-cosine':['user-cosine',cv_patk_output['user-cosine'][1],cv_rmse_output['user-cosine'][1],cv_ratk_output['user-cosine'][1],cv_rprec_output['user-cosine'][1]],\n",
    "             'useraverage':['useraverage',cv_patk_output['useraverage'][1],cv_rmse_output['useraverage'][1],cv_ratk_output['useraverage'][1],cv_rprec_output['useraverage'][1]]}\n",
    "\n",
    "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Method','         P@K', '               RMSE', '          R@K','                 RPREC'))\n",
    "for key, value in output_dict.items():\n",
    "    method, patk, rmse, ratk, rprec = value\n",
    "    print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format(method, patk, rmse, ratk, rprec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD0cOnZI80Bf"
   },
   "source": [
    "Considering the results provided above, we see that for Precision@k, user-user with cosine similarity is the top performing method. For RMSE, Recall at k and Rprecision also this method is the top performing model, so overall we see that this model is the best considering all metrics. Compared to the popularity and user average, this method is more complicated and leverages information of the user ratings more intelligently by using the information of similar users instead of averaging over all users or taking into account the popularity of the items for making recommendation. The difference between this method and item-cosine is that here we use user similarities and in the previous sections we saw that we have denser information about users than items, so it is expected that the user-cosine performs better than the item-cosine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUHOF_4H81Au"
   },
   "source": [
    "Please note tha good performance on RMSE imply good performance on ranking metrics and vice versa. RMSE penalizes high ratings and low ratings equally. In recommender systems, we are mostly interested in finding the top ranked items to provide to the user and the good performance of the system on low ratings is not as important as the high ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCLiF-SP9DYi"
   },
   "source": [
    "##Similarity Evaluation\n",
    "Let's go through the list of movies and pick three not-so-popular movies that we know well and list the top 5 most similar movie names according to item-item cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4Wur8vI8-2y"
   },
   "outputs": [],
   "source": [
    "train_matrix = dataPreprocessor(rating_df_train,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n",
    "np.shape(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82V77_MK9iw5"
   },
   "outputs": [],
   "source": [
    "train_matrix_item=np.transpose(train_matrix)\n",
    "ii_similarity=SimBasedRecSys.cosine(train_matrix_item)\n",
    "#Movie1: ID97: Dances with Wolves\n",
    "x=np.argsort(ii_similarity[96,:])[-6:]\n",
    "#np.shape(train_matrix_item)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbP9TDUX9mzD"
   },
   "source": [
    "Most similar movies to movie 1: Forrest Gump (1994) (both Dramas), E.T. the Extra-Terrestrial (both adventure), Field of Dreams (1989)(both dramas), Raiders of the Lost Ark(action and adventure), When Harry Met Sally... (1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_cseapu9rv8"
   },
   "outputs": [],
   "source": [
    "#Movie2: ID178: 12 Angry Men\n",
    "y=np.argsort(ii_similarity[177,:])[-6:]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuwuKjbE9uBb"
   },
   "source": [
    "Most similar movies to movie 2: Breakfast at Tiffany's (1961), Raising Arizona (1987)(both well-known crime related movies), Raiders of the Lost Ark (1981), Amadeus (1984), Hoop Dreams (1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONvjzCDp9zMK"
   },
   "outputs": [],
   "source": [
    "#Most similar movies to movie 3(Cinema Paradiso): Like Water For Chocolate, Mediterraneo (1991), Piano, The (1993), Unbearable Lightness of Being, The (1988), Jean de Florette (1986)\n",
    "z=np.argsort(ii_similarity[169,:])[-6:]\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp3vd-R493wZ"
   },
   "source": [
    "Gistogram of the number of ratings per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loP7MJTQ9_Xp"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_matrix = dataPreprocessor(rating_df_test,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n",
    "train_matrix = dataPreprocessor(rating_df_train,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_phgMWQ-Bd5"
   },
   "outputs": [],
   "source": [
    "temp_matrix = np.zeros(train_matrix.shape)\n",
    "temp_matrix[train_matrix.nonzero()] = 1\n",
    "ratesPerUser=np.sum(train_matrix, axis=1)\n",
    "_ = plt.hist(ratesPerUser, bins='auto')\n",
    "plt.show()\n",
    "#print (hist)\n",
    "#print (\"Size of the bins          : \", bin_edges)\n",
    "#plt.bar(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UioPQ96u-M0a"
   },
   "source": [
    "We pick 250 as a threshold  that divides users with few ratings and those with a moderate to large number of ratings. Evaluate the RMSE of user-user and item-item collaborative filtering on users below and above the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DO7ikjZq-Jkk"
   },
   "outputs": [],
   "source": [
    "indices_above=np.array([i for i,v in enumerate(ratesPerUser) if v > 250])\n",
    "indices_below=np.array([i for i,v in enumerate(ratesPerUser) if v < 250])\n",
    "rating_df_train_above=rating_df_train.copy()\n",
    "rating_df_train_below=rating_df_train.copy()\n",
    "for index, row in rating_df_train_above.iterrows():\n",
    "  if index in indices_below:\n",
    "    rating_df_train_above.iloc[index]=0\n",
    "\n",
    "for index,row in rating_df_train_below.iterrows():\n",
    "  if index in indices_above:\n",
    "    rating_df_train_below.iloc[index]=0\n",
    "\n",
    "ratesPerUser_test=np.sum(test_matrix, axis=1)\n",
    "indices_above_test=np.array([i for i,v in enumerate(ratesPerUser_test) if v > 250])\n",
    "indices_below_test=np.array([i for i,v in enumerate(ratesPerUser_test) if v < 250])\n",
    "rating_df_test_above=rating_df_test.copy()\n",
    "rating_df_test_below=rating_df_test.copy()\n",
    "for index, row in rating_df_test_above.iterrows():\n",
    "  if index in indices_below:\n",
    "    rating_df_test_above.iloc[index]=0\n",
    "\n",
    "for index,row in rating_df_test_below.iterrows():\n",
    "  if index in indices_above:\n",
    "    rating_df_test_below.iloc[index]=0\n",
    "\n",
    "#Above Threshold\n",
    "user_cosine_recsys = SimBasedRecSys('user','cosine')\n",
    "user_cosine_recsys.predict_all(rating_df_train_above,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n",
    "user_cosine_recsys.getModel()\n",
    "pred_col=user_cosine_recsys.getPredColName()\n",
    "prediction=user_cosine_recsys.evaluate_test(rating_df_test_above,copy=True)\n",
    "rmse1=CrossValidation.rmse(prediction,None,None,None,pred_col)\n",
    "rmse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNoeq6M5-L46"
   },
   "outputs": [],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
    "item_cosine_recsys.predict_all(rating_df_train_above,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n",
    "item_cosine_recsys.getModel()\n",
    "pred_col=item_cosine_recsys.getPredColName()\n",
    "prediction=item_cosine_recsys.evaluate_test(rating_df_test_above,copy=True)\n",
    "rmse2=CrossValidation.rmse(prediction,None,None,None,pred_col)\n",
    "rmse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AE5sO92-ky2"
   },
   "outputs": [],
   "source": [
    "#Below Threshold\n",
    "user_cosine_recsys_below = SimBasedRecSys('user','cosine')\n",
    "user_cosine_recsys_below.predict_all(rating_df_train_below,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n",
    "user_cosine_recsys_below.getModel()\n",
    "pred_col=user_cosine_recsys_below.getPredColName()\n",
    "prediction=user_cosine_recsys_below.evaluate_test(rating_df_test_below,copy=True)\n",
    "rmse3=CrossValidation.rmse(prediction,None,None,None,pred_col)\n",
    "rmse3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYedERBH-ogT"
   },
   "outputs": [],
   "source": [
    "item_cosine_recsys_below = SimBasedRecSys('item','cosine')\n",
    "item_cosine_recsys_below.predict_all(rating_df_train_below,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))\n",
    "item_cosine_recsys_below.getModel()\n",
    "pred_col=item_cosine_recsys_below.getPredColName()\n",
    "prediction=item_cosine_recsys_below.evaluate_test(rating_df_test_below,copy=True)\n",
    "rmse4=CrossValidation.rmse(prediction,None,None,None,pred_col)\n",
    "rmse4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn1OoETS-yoI"
   },
   "source": [
    "In both user-user and item-item similarities, we see that by considering users below threshold and training and testing on them, the rmse decreases. We can postulate that since the number of these users is much more than the users with more than the threshold ratings, their ratings forms the overall distribution of the ratings and testing on them yields less error. Intuitively, we may assume that users above the threshold provide more credible information and the error on them might be expected to decrease, but here we see that maybe due to the higher number of below threshold users, the RMSE decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2zIdhOC-309"
   },
   "source": [
    "##Using SVD as a Factorization-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imDOlvSh-zU6"
   },
   "outputs": [],
   "source": [
    "class CompetitionRecSys(object):\n",
    "    \"\"\"\n",
    "    You can define new methods if you need. Don't use global variables in the class. \n",
    "    \"\"\"\n",
    "    def __init__(self, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "        Initialization of the class\n",
    "        1. Make sure to fill out self.pred_column_name, the name you give  to your competition method\n",
    "        \n",
    "        \"\"\"\n",
    "        self.pred_column_name = 'advanced'\n",
    "        self.processor = processor\n",
    "\n",
    "    def predict_all(self, train_vec, num_user, num_item):\n",
    "        \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            num_user: scalar. number of users\n",
    "            num_item: scalar. number of items\n",
    "        OUTPUT:\n",
    "            no return... \n",
    "        \n",
    "        NOTES:\n",
    "            This function is where you train your model\n",
    "        \"\"\"\n",
    "                \n",
    "\n",
    "        train_matrix = self.processor(train_vec, num_user, num_item)\n",
    "        U, s, V= np.linalg.svd(train_matrix,full_matrices=False)\n",
    "        s=np.diag(s)\n",
    "        k=4\n",
    "        s=s[0:k,0:k]\n",
    "        U=U[:,0:k]\n",
    "        V=V[0:k,:]\n",
    "        s_root=sqrtm(s)\n",
    "        Usk=np.dot(U,s_root)\n",
    "        skV=np.dot(s_root,V)\n",
    "        UsV = np.dot(Usk, skV)\n",
    "        x_pred=UsV\n",
    "        self.__model= x_pred\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "\n",
    "            NOTES:\n",
    "            This function is where your model makes prediction \n",
    "            Please fill out: prediction.loc[index, self.pred_column_name] = None                            \n",
    "                              \n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
    "        else:\n",
    "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "\n",
    "        return prediction\n",
    "          \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        self.__model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCWNsVJy_ZOt"
   },
   "outputs": [],
   "source": [
    "competition = CompetitionRecSys()\n",
    "algorithm_instances = [competition]\n",
    "cv_rp = CrossValidation('RPrecision')\n",
    "rp = cv_rp.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
